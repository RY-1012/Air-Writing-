#  Air Writing Recognition System (Green Brush Based)

An **AI-powered Air Writing Recognition System** that allows users to write characters in the air using a **green-colored pointer/object**.  
The system captures strokes via a webcam, processes only green pixels, and recognizes handwritten characters using a **custom-trained CNN model**.


## Sample Output
![Image]=(https://github.com/user-attachments/assets/d743167e-935d-4665-af47-cf9c362b7e5d)

---

## ğŸ“Œ Features

- âœ… Air writing using **green brush detection (HSV-based)**
- âœ… Personal dataset collection
- âœ… Custom CNN training (**TensorFlow / Keras**)
- âœ… Real-time prediction via webcam
- âœ… Noise-free detection (only green strokes considered)
- âœ… Works offline

---

## ğŸ› ï¸ Tech Stack

- **Python 3.9+**
- **OpenCV** â€“ video capture & image processing
- **NumPy** â€“ numerical operations
- **TensorFlow / Keras** â€“ CNN model training & prediction

---

## ğŸ“‚ Project Structure

AirWritingProject/
â”‚
â”œâ”€â”€ air_writing_collect.py # Collect green air-written samples
â”œâ”€â”€ train_personal_model.py # Train CNN on collected samples
â”œâ”€â”€ air_writing_predict.py # Real-time prediction
â”œâ”€â”€ personal_model.h5 # Trained model (generated)
â”œâ”€â”€ labels.txt # Class labels
â”œâ”€â”€ samples/ # Dataset folder
â”‚ â”œâ”€â”€ A/
â”‚ â”œâ”€â”€ B/
â”‚ â””â”€â”€ C/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## âš™ï¸ Installation & Setup
2ï¸âƒ£ Install Requirements
pip install -r requirements.txt

python air_writing_collect.py

##Instructions

Use a green-colored object (pen cap, marker, tape)

Draw characters in the air

Press s â†’ enter character label (A, B, C, etc.)

Collect 5â€“10 samples per character

## ğŸ§  Step 2: Train the Model
python train_personal_model.py

##Output

Trains a CNN on your samples

Generates:

personal_model.h5

labels.txt

##ğŸ”® Step 3: Predict Air-Written Characters
python air_writing_predict.py

Controls

Move green object â†’ draw

r â†’ recognize character

c â†’ clear canvas

q â†’ quit

Prediction result is printed in the terminal.

##ğŸ¯ How It Works (Pipeline)

Webcam captures video frames

Convert frames to HSV color space

Extract only green pixels

Draw strokes on a virtual canvas

Resize to 28Ã—28 grayscale image

CNN predicts the character.

##ğŸ§ª Model Details

Input Shape: 28 Ã— 28 Ã— 1

Architecture:

Conv2D â†’ MaxPooling

Conv2D â†’ MaxPooling

Dense â†’ Softmax

Optimizer: Adam

Loss Function: Categorical Crossentropy

##ğŸ‘¨â€ğŸ’» Author

Rahul Yadav
B.Tech CSE (AI & ML)

Atharva Ghayal
B.tech CSE (AI & DS)

Kavin Nadar
B.tech CSE (AI & ML)

Branden Machado
B.tech CSE (AI & ML)
